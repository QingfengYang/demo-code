{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import xgboost as xgb \n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=1000):\n",
    "    param={}\n",
    "    param['objective']='multi:softprob'\n",
    "    param['eta']=0.1\n",
    "    param['max_depth']=6\n",
    "    param['silent']=1\n",
    "    param['num_class']=3\n",
    "    param['eval_metric']='mlogloss'\n",
    "    param['min_child_weigh']=1\n",
    "    param['subsample']=0.7\n",
    "    param['colsample_bytree']=0.7\n",
    "    param['seed']=seed_val\n",
    "    num_rounds=num_rounds\n",
    "    \n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "    \n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlst = [(xgtrain, 'train'), (xgtest, 'test')]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlst, early_stopping_rounds=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "        \n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n",
      "(74659, 14)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/yangqingfeng/data/open_data/kaggle/two-sigma/\"\n",
    "train_file = data_path + \"train.json\"\n",
    "test_file = data_path + \"test.json\"\n",
    "train_df = pd.read_json(train_file)\n",
    "test_df = pd.read_json(test_file)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = ['bathrooms', 'bedrooms','latitude', 'longitude', 'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of photos #\n",
    "train_df['num_photos'] = train_df['photos'].apply(len)\n",
    "test_df['num_photos'] = test_df['photos'].apply(len)\n",
    "\n",
    "#count of \"features\"\n",
    "train_df['num_features'] = train_df['features'].apply(len)\n",
    "test_df['num_features'] = test_df['features'].apply(len)\n",
    "\n",
    "#count of words present in descriptions column #\n",
    "train_df['num_description_words'] = train_df['description'].apply(lambda x: len(x.split(\" \")))\n",
    "test_df['num_description_words'] = test_df['description'].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "# convert the created column to datetime object so as to extract more features\n",
    "train_df['created'] = pd.to_datetime(train_df['created'])\n",
    "test_df['created'] = pd.to_datetime(test_df['created'])\n",
    "\n",
    "# Let us extract some features like year, month, day, hour from date columns #\n",
    "train_df['created_year'] = train_df['created'].dt.year\n",
    "train_df['created_month'] = train_df['created'].dt.month\n",
    "train_df['created_day'] = train_df['created'].dt.day\n",
    "train_df['created_hour'] = train_df['created'].dt.hour\n",
    "\n",
    "test_df['created_year'] = test_df['created'].dt.year\n",
    "test_df['created_month'] = test_df['created'].dt.month\n",
    "test_df['created_day'] = test_df['created'].dt.day\n",
    "test_df['created_hour'] = test_df['created'].dt.hour\n",
    "\n",
    "# adding all these new features to use list #\n",
    "features_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\", \n",
    "                        \"created_year\", \"created_month\", \"created_day\", \"created_hour\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\n",
    "for f in categorical:\n",
    "    if train_df[f].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n",
    "        train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "        test_df[f] = lbl.transform(list(test_df[f].values))\n",
    "        features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10                                                         \n",
       "10000     Doorman Elevator Fitness_Center Cats_Allowed D...\n",
       "100004    Laundry_In_Building Dishwasher Hardwood_Floors...\n",
       "100007                               Hardwood_Floors No_Fee\n",
       "100013                                              Pre-War\n",
       "Name: features, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['features'] = train_df['features'].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "test_df['features'] = test_df['features'].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "train_df['features'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = CountVectorizer(stop_words='english', max_features=200)\n",
    "tr_spare = tfidf.fit_transform(train_df['features'])\n",
    "te_spare = tfidf.transform(test_df['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 216) (74659, 216)\n"
     ]
    }
   ],
   "source": [
    "train_X = sparse.hstack([train_df[features_to_use], tr_spare]).tocsr()\n",
    "test_X = sparse.hstack([test_df[features_to_use], te_spare]).tocsr()\n",
    "\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "print(train_X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.04083\ttest-mlogloss:1.04189\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 20 rounds.\n",
      "[1]\ttrain-mlogloss:0.989262\ttest-mlogloss:0.991126\n",
      "[2]\ttrain-mlogloss:0.943198\ttest-mlogloss:0.946199\n",
      "[3]\ttrain-mlogloss:0.906756\ttest-mlogloss:0.910371\n",
      "[4]\ttrain-mlogloss:0.876267\ttest-mlogloss:0.880702\n",
      "[5]\ttrain-mlogloss:0.84588\ttest-mlogloss:0.851287\n",
      "[6]\ttrain-mlogloss:0.820024\ttest-mlogloss:0.826144\n",
      "[7]\ttrain-mlogloss:0.796375\ttest-mlogloss:0.803423\n",
      "[8]\ttrain-mlogloss:0.775781\ttest-mlogloss:0.783616\n",
      "[9]\ttrain-mlogloss:0.757724\ttest-mlogloss:0.766164\n",
      "[10]\ttrain-mlogloss:0.741542\ttest-mlogloss:0.750651\n",
      "[11]\ttrain-mlogloss:0.728622\ttest-mlogloss:0.738387\n",
      "[12]\ttrain-mlogloss:0.715143\ttest-mlogloss:0.725583\n",
      "[13]\ttrain-mlogloss:0.70431\ttest-mlogloss:0.715483\n",
      "[14]\ttrain-mlogloss:0.693668\ttest-mlogloss:0.705751\n",
      "[15]\ttrain-mlogloss:0.684657\ttest-mlogloss:0.697585\n",
      "[16]\ttrain-mlogloss:0.675546\ttest-mlogloss:0.689161\n",
      "[17]\ttrain-mlogloss:0.667123\ttest-mlogloss:0.681515\n",
      "[18]\ttrain-mlogloss:0.658718\ttest-mlogloss:0.67386\n",
      "[19]\ttrain-mlogloss:0.651954\ttest-mlogloss:0.667922\n",
      "[20]\ttrain-mlogloss:0.645284\ttest-mlogloss:0.662042\n",
      "[21]\ttrain-mlogloss:0.639939\ttest-mlogloss:0.657425\n",
      "[22]\ttrain-mlogloss:0.635018\ttest-mlogloss:0.653291\n",
      "[23]\ttrain-mlogloss:0.62859\ttest-mlogloss:0.647821\n",
      "[24]\ttrain-mlogloss:0.624467\ttest-mlogloss:0.644443\n",
      "[25]\ttrain-mlogloss:0.620045\ttest-mlogloss:0.64067\n",
      "[26]\ttrain-mlogloss:0.616724\ttest-mlogloss:0.638089\n",
      "[27]\ttrain-mlogloss:0.612526\ttest-mlogloss:0.634734\n",
      "[28]\ttrain-mlogloss:0.60836\ttest-mlogloss:0.631308\n",
      "[29]\ttrain-mlogloss:0.604826\ttest-mlogloss:0.628612\n",
      "[30]\ttrain-mlogloss:0.602166\ttest-mlogloss:0.626573\n",
      "[31]\ttrain-mlogloss:0.598397\ttest-mlogloss:0.623766\n",
      "[32]\ttrain-mlogloss:0.595384\ttest-mlogloss:0.621477\n",
      "[33]\ttrain-mlogloss:0.592704\ttest-mlogloss:0.619584\n",
      "[34]\ttrain-mlogloss:0.590152\ttest-mlogloss:0.617897\n",
      "[35]\ttrain-mlogloss:0.587085\ttest-mlogloss:0.615554\n",
      "[36]\ttrain-mlogloss:0.584521\ttest-mlogloss:0.613831\n",
      "[37]\ttrain-mlogloss:0.582067\ttest-mlogloss:0.612029\n",
      "[38]\ttrain-mlogloss:0.579495\ttest-mlogloss:0.61021\n",
      "[39]\ttrain-mlogloss:0.577421\ttest-mlogloss:0.608746\n",
      "[40]\ttrain-mlogloss:0.575168\ttest-mlogloss:0.607179\n",
      "[41]\ttrain-mlogloss:0.572857\ttest-mlogloss:0.605785\n",
      "[42]\ttrain-mlogloss:0.570605\ttest-mlogloss:0.604412\n",
      "[43]\ttrain-mlogloss:0.568737\ttest-mlogloss:0.603041\n",
      "[44]\ttrain-mlogloss:0.56625\ttest-mlogloss:0.601489\n",
      "[45]\ttrain-mlogloss:0.564187\ttest-mlogloss:0.600389\n",
      "[46]\ttrain-mlogloss:0.562294\ttest-mlogloss:0.599243\n",
      "[47]\ttrain-mlogloss:0.560444\ttest-mlogloss:0.598453\n",
      "[48]\ttrain-mlogloss:0.5584\ttest-mlogloss:0.597442\n",
      "[49]\ttrain-mlogloss:0.55645\ttest-mlogloss:0.596306\n",
      "[50]\ttrain-mlogloss:0.554815\ttest-mlogloss:0.595347\n",
      "[51]\ttrain-mlogloss:0.55311\ttest-mlogloss:0.594228\n",
      "[52]\ttrain-mlogloss:0.55132\ttest-mlogloss:0.593309\n",
      "[53]\ttrain-mlogloss:0.549684\ttest-mlogloss:0.592372\n",
      "[54]\ttrain-mlogloss:0.547885\ttest-mlogloss:0.591657\n",
      "[55]\ttrain-mlogloss:0.547005\ttest-mlogloss:0.591192\n",
      "[56]\ttrain-mlogloss:0.544934\ttest-mlogloss:0.589977\n",
      "[57]\ttrain-mlogloss:0.543339\ttest-mlogloss:0.589011\n",
      "[58]\ttrain-mlogloss:0.541973\ttest-mlogloss:0.58858\n",
      "[59]\ttrain-mlogloss:0.540673\ttest-mlogloss:0.588037\n",
      "[60]\ttrain-mlogloss:0.539058\ttest-mlogloss:0.587192\n",
      "[61]\ttrain-mlogloss:0.537443\ttest-mlogloss:0.58645\n",
      "[62]\ttrain-mlogloss:0.535815\ttest-mlogloss:0.585637\n",
      "[63]\ttrain-mlogloss:0.534154\ttest-mlogloss:0.584834\n",
      "[64]\ttrain-mlogloss:0.53309\ttest-mlogloss:0.584394\n",
      "[65]\ttrain-mlogloss:0.531619\ttest-mlogloss:0.583853\n",
      "[66]\ttrain-mlogloss:0.530558\ttest-mlogloss:0.583343\n",
      "[67]\ttrain-mlogloss:0.52913\ttest-mlogloss:0.582833\n",
      "[68]\ttrain-mlogloss:0.52792\ttest-mlogloss:0.58221\n",
      "[69]\ttrain-mlogloss:0.526773\ttest-mlogloss:0.581922\n",
      "[70]\ttrain-mlogloss:0.525763\ttest-mlogloss:0.581514\n",
      "[71]\ttrain-mlogloss:0.524279\ttest-mlogloss:0.581144\n",
      "[72]\ttrain-mlogloss:0.523199\ttest-mlogloss:0.580688\n",
      "[73]\ttrain-mlogloss:0.521784\ttest-mlogloss:0.580271\n",
      "[74]\ttrain-mlogloss:0.520605\ttest-mlogloss:0.579838\n",
      "[75]\ttrain-mlogloss:0.519506\ttest-mlogloss:0.579419\n",
      "[76]\ttrain-mlogloss:0.518262\ttest-mlogloss:0.57901\n",
      "[77]\ttrain-mlogloss:0.517257\ttest-mlogloss:0.578791\n",
      "[78]\ttrain-mlogloss:0.515718\ttest-mlogloss:0.577976\n",
      "[79]\ttrain-mlogloss:0.514836\ttest-mlogloss:0.577734\n",
      "[80]\ttrain-mlogloss:0.513701\ttest-mlogloss:0.577327\n",
      "[81]\ttrain-mlogloss:0.512712\ttest-mlogloss:0.577014\n",
      "[82]\ttrain-mlogloss:0.511587\ttest-mlogloss:0.576494\n",
      "[83]\ttrain-mlogloss:0.510513\ttest-mlogloss:0.576026\n",
      "[84]\ttrain-mlogloss:0.509559\ttest-mlogloss:0.575728\n",
      "[85]\ttrain-mlogloss:0.5084\ttest-mlogloss:0.575366\n",
      "[86]\ttrain-mlogloss:0.507459\ttest-mlogloss:0.575047\n",
      "[87]\ttrain-mlogloss:0.506635\ttest-mlogloss:0.574672\n",
      "[88]\ttrain-mlogloss:0.505728\ttest-mlogloss:0.574419\n",
      "[89]\ttrain-mlogloss:0.504808\ttest-mlogloss:0.573918\n",
      "[90]\ttrain-mlogloss:0.503907\ttest-mlogloss:0.573601\n",
      "[91]\ttrain-mlogloss:0.503077\ttest-mlogloss:0.57355\n",
      "[92]\ttrain-mlogloss:0.502047\ttest-mlogloss:0.57319\n",
      "[93]\ttrain-mlogloss:0.501234\ttest-mlogloss:0.572987\n",
      "[94]\ttrain-mlogloss:0.500336\ttest-mlogloss:0.572589\n",
      "[95]\ttrain-mlogloss:0.499596\ttest-mlogloss:0.572401\n",
      "[96]\ttrain-mlogloss:0.498564\ttest-mlogloss:0.571995\n",
      "[97]\ttrain-mlogloss:0.497849\ttest-mlogloss:0.571821\n",
      "[98]\ttrain-mlogloss:0.496989\ttest-mlogloss:0.571618\n",
      "[99]\ttrain-mlogloss:0.495851\ttest-mlogloss:0.571262\n",
      "[100]\ttrain-mlogloss:0.495067\ttest-mlogloss:0.571116\n",
      "[101]\ttrain-mlogloss:0.494149\ttest-mlogloss:0.570694\n",
      "[102]\ttrain-mlogloss:0.493289\ttest-mlogloss:0.57052\n",
      "[103]\ttrain-mlogloss:0.492531\ttest-mlogloss:0.570299\n",
      "[104]\ttrain-mlogloss:0.491332\ttest-mlogloss:0.570036\n",
      "[105]\ttrain-mlogloss:0.490388\ttest-mlogloss:0.569806\n",
      "[106]\ttrain-mlogloss:0.489755\ttest-mlogloss:0.569677\n",
      "[107]\ttrain-mlogloss:0.489117\ttest-mlogloss:0.569504\n",
      "[108]\ttrain-mlogloss:0.488176\ttest-mlogloss:0.569282\n",
      "[109]\ttrain-mlogloss:0.487206\ttest-mlogloss:0.568932\n",
      "[110]\ttrain-mlogloss:0.486327\ttest-mlogloss:0.568567\n",
      "[111]\ttrain-mlogloss:0.485644\ttest-mlogloss:0.568338\n",
      "[112]\ttrain-mlogloss:0.484705\ttest-mlogloss:0.568245\n",
      "[113]\ttrain-mlogloss:0.483607\ttest-mlogloss:0.568178\n",
      "[114]\ttrain-mlogloss:0.482857\ttest-mlogloss:0.56805\n",
      "[115]\ttrain-mlogloss:0.481907\ttest-mlogloss:0.567783\n",
      "[116]\ttrain-mlogloss:0.481222\ttest-mlogloss:0.567711\n",
      "[117]\ttrain-mlogloss:0.480445\ttest-mlogloss:0.567509\n",
      "[118]\ttrain-mlogloss:0.479651\ttest-mlogloss:0.567345\n",
      "[119]\ttrain-mlogloss:0.47919\ttest-mlogloss:0.567217\n",
      "[120]\ttrain-mlogloss:0.478597\ttest-mlogloss:0.567022\n",
      "[121]\ttrain-mlogloss:0.478039\ttest-mlogloss:0.566853\n",
      "[122]\ttrain-mlogloss:0.477373\ttest-mlogloss:0.566759\n",
      "[123]\ttrain-mlogloss:0.476426\ttest-mlogloss:0.566744\n",
      "[124]\ttrain-mlogloss:0.475629\ttest-mlogloss:0.566599\n",
      "[125]\ttrain-mlogloss:0.475094\ttest-mlogloss:0.566431\n",
      "[126]\ttrain-mlogloss:0.474208\ttest-mlogloss:0.566173\n",
      "[127]\ttrain-mlogloss:0.473659\ttest-mlogloss:0.566099\n",
      "[128]\ttrain-mlogloss:0.472801\ttest-mlogloss:0.565857\n",
      "[129]\ttrain-mlogloss:0.472214\ttest-mlogloss:0.565709\n",
      "[130]\ttrain-mlogloss:0.471682\ttest-mlogloss:0.565421\n",
      "[131]\ttrain-mlogloss:0.470854\ttest-mlogloss:0.565336\n",
      "[132]\ttrain-mlogloss:0.470306\ttest-mlogloss:0.56511\n",
      "[133]\ttrain-mlogloss:0.469786\ttest-mlogloss:0.564927\n",
      "[134]\ttrain-mlogloss:0.468895\ttest-mlogloss:0.564899\n",
      "[135]\ttrain-mlogloss:0.468146\ttest-mlogloss:0.564662\n",
      "[136]\ttrain-mlogloss:0.467709\ttest-mlogloss:0.564508\n",
      "[137]\ttrain-mlogloss:0.466698\ttest-mlogloss:0.564229\n",
      "[138]\ttrain-mlogloss:0.465892\ttest-mlogloss:0.564097\n",
      "[139]\ttrain-mlogloss:0.465301\ttest-mlogloss:0.563908\n",
      "[140]\ttrain-mlogloss:0.464668\ttest-mlogloss:0.563675\n",
      "[141]\ttrain-mlogloss:0.46408\ttest-mlogloss:0.563594\n",
      "[142]\ttrain-mlogloss:0.463447\ttest-mlogloss:0.563429\n",
      "[143]\ttrain-mlogloss:0.46267\ttest-mlogloss:0.563204\n",
      "[144]\ttrain-mlogloss:0.462117\ttest-mlogloss:0.56311\n",
      "[145]\ttrain-mlogloss:0.461612\ttest-mlogloss:0.562998\n",
      "[146]\ttrain-mlogloss:0.461075\ttest-mlogloss:0.562773\n",
      "[147]\ttrain-mlogloss:0.46037\ttest-mlogloss:0.562577\n",
      "[148]\ttrain-mlogloss:0.459845\ttest-mlogloss:0.562524\n",
      "[149]\ttrain-mlogloss:0.459048\ttest-mlogloss:0.562214\n",
      "[150]\ttrain-mlogloss:0.458436\ttest-mlogloss:0.56213\n",
      "[151]\ttrain-mlogloss:0.457913\ttest-mlogloss:0.562024\n",
      "[152]\ttrain-mlogloss:0.45726\ttest-mlogloss:0.561971\n",
      "[153]\ttrain-mlogloss:0.45658\ttest-mlogloss:0.56182\n",
      "[154]\ttrain-mlogloss:0.455981\ttest-mlogloss:0.561773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[155]\ttrain-mlogloss:0.45534\ttest-mlogloss:0.561538\n",
      "[156]\ttrain-mlogloss:0.454548\ttest-mlogloss:0.561303\n",
      "[157]\ttrain-mlogloss:0.453966\ttest-mlogloss:0.561265\n",
      "[158]\ttrain-mlogloss:0.453185\ttest-mlogloss:0.561127\n",
      "[159]\ttrain-mlogloss:0.45273\ttest-mlogloss:0.561078\n",
      "[160]\ttrain-mlogloss:0.452184\ttest-mlogloss:0.560962\n",
      "[161]\ttrain-mlogloss:0.451701\ttest-mlogloss:0.560863\n",
      "[162]\ttrain-mlogloss:0.451049\ttest-mlogloss:0.56065\n",
      "[163]\ttrain-mlogloss:0.450509\ttest-mlogloss:0.560585\n",
      "[164]\ttrain-mlogloss:0.449969\ttest-mlogloss:0.560559\n",
      "[165]\ttrain-mlogloss:0.449312\ttest-mlogloss:0.560478\n",
      "[166]\ttrain-mlogloss:0.448838\ttest-mlogloss:0.560435\n",
      "[167]\ttrain-mlogloss:0.448325\ttest-mlogloss:0.560298\n",
      "[168]\ttrain-mlogloss:0.447602\ttest-mlogloss:0.560238\n",
      "[169]\ttrain-mlogloss:0.446949\ttest-mlogloss:0.560183\n",
      "[170]\ttrain-mlogloss:0.446123\ttest-mlogloss:0.560033\n",
      "[171]\ttrain-mlogloss:0.445499\ttest-mlogloss:0.559895\n",
      "[172]\ttrain-mlogloss:0.444682\ttest-mlogloss:0.55993\n",
      "[173]\ttrain-mlogloss:0.444139\ttest-mlogloss:0.559769\n",
      "[174]\ttrain-mlogloss:0.443647\ttest-mlogloss:0.559557\n",
      "[175]\ttrain-mlogloss:0.442876\ttest-mlogloss:0.559426\n",
      "[176]\ttrain-mlogloss:0.44241\ttest-mlogloss:0.559367\n",
      "[177]\ttrain-mlogloss:0.441685\ttest-mlogloss:0.559132\n",
      "[178]\ttrain-mlogloss:0.44115\ttest-mlogloss:0.559147\n",
      "[179]\ttrain-mlogloss:0.440607\ttest-mlogloss:0.559175\n",
      "[180]\ttrain-mlogloss:0.439954\ttest-mlogloss:0.559238\n",
      "[181]\ttrain-mlogloss:0.439284\ttest-mlogloss:0.559156\n",
      "[182]\ttrain-mlogloss:0.438792\ttest-mlogloss:0.559067\n",
      "[183]\ttrain-mlogloss:0.438273\ttest-mlogloss:0.559028\n",
      "[184]\ttrain-mlogloss:0.437544\ttest-mlogloss:0.558744\n",
      "[185]\ttrain-mlogloss:0.437121\ttest-mlogloss:0.558682\n",
      "[186]\ttrain-mlogloss:0.436692\ttest-mlogloss:0.558557\n",
      "[187]\ttrain-mlogloss:0.435971\ttest-mlogloss:0.558434\n",
      "[188]\ttrain-mlogloss:0.435344\ttest-mlogloss:0.558422\n",
      "[189]\ttrain-mlogloss:0.434598\ttest-mlogloss:0.558299\n",
      "[190]\ttrain-mlogloss:0.434086\ttest-mlogloss:0.558232\n",
      "[191]\ttrain-mlogloss:0.433634\ttest-mlogloss:0.558193\n",
      "[192]\ttrain-mlogloss:0.433222\ttest-mlogloss:0.558122\n",
      "[193]\ttrain-mlogloss:0.432537\ttest-mlogloss:0.557943\n",
      "[194]\ttrain-mlogloss:0.432023\ttest-mlogloss:0.557923\n",
      "[195]\ttrain-mlogloss:0.431428\ttest-mlogloss:0.55787\n",
      "[196]\ttrain-mlogloss:0.43096\ttest-mlogloss:0.557795\n",
      "[197]\ttrain-mlogloss:0.430475\ttest-mlogloss:0.557725\n",
      "[198]\ttrain-mlogloss:0.429873\ttest-mlogloss:0.557715\n",
      "[199]\ttrain-mlogloss:0.429297\ttest-mlogloss:0.557621\n",
      "[200]\ttrain-mlogloss:0.4289\ttest-mlogloss:0.557623\n",
      "[201]\ttrain-mlogloss:0.428421\ttest-mlogloss:0.557603\n",
      "[202]\ttrain-mlogloss:0.428042\ttest-mlogloss:0.557549\n",
      "[203]\ttrain-mlogloss:0.427257\ttest-mlogloss:0.557369\n",
      "[204]\ttrain-mlogloss:0.426654\ttest-mlogloss:0.557312\n",
      "[205]\ttrain-mlogloss:0.426163\ttest-mlogloss:0.557172\n",
      "[206]\ttrain-mlogloss:0.425524\ttest-mlogloss:0.557036\n",
      "[207]\ttrain-mlogloss:0.425017\ttest-mlogloss:0.557001\n",
      "[208]\ttrain-mlogloss:0.424652\ttest-mlogloss:0.556956\n",
      "[209]\ttrain-mlogloss:0.424047\ttest-mlogloss:0.556909\n",
      "[210]\ttrain-mlogloss:0.423599\ttest-mlogloss:0.55692\n",
      "[211]\ttrain-mlogloss:0.42305\ttest-mlogloss:0.5569\n",
      "[212]\ttrain-mlogloss:0.422548\ttest-mlogloss:0.556891\n",
      "[213]\ttrain-mlogloss:0.421863\ttest-mlogloss:0.556682\n",
      "[214]\ttrain-mlogloss:0.421365\ttest-mlogloss:0.556496\n",
      "[215]\ttrain-mlogloss:0.420805\ttest-mlogloss:0.556369\n",
      "[216]\ttrain-mlogloss:0.420339\ttest-mlogloss:0.556365\n",
      "[217]\ttrain-mlogloss:0.419711\ttest-mlogloss:0.556286\n",
      "[218]\ttrain-mlogloss:0.419185\ttest-mlogloss:0.556147\n",
      "[219]\ttrain-mlogloss:0.418536\ttest-mlogloss:0.556293\n",
      "[220]\ttrain-mlogloss:0.417989\ttest-mlogloss:0.55619\n",
      "[221]\ttrain-mlogloss:0.41755\ttest-mlogloss:0.556139\n",
      "[222]\ttrain-mlogloss:0.417058\ttest-mlogloss:0.556129\n",
      "[223]\ttrain-mlogloss:0.416648\ttest-mlogloss:0.556053\n",
      "[224]\ttrain-mlogloss:0.4161\ttest-mlogloss:0.556046\n",
      "[225]\ttrain-mlogloss:0.415591\ttest-mlogloss:0.556055\n",
      "[226]\ttrain-mlogloss:0.415111\ttest-mlogloss:0.555955\n",
      "[227]\ttrain-mlogloss:0.414685\ttest-mlogloss:0.556005\n",
      "[228]\ttrain-mlogloss:0.414197\ttest-mlogloss:0.555948\n",
      "[229]\ttrain-mlogloss:0.413724\ttest-mlogloss:0.555929\n",
      "[230]\ttrain-mlogloss:0.413345\ttest-mlogloss:0.55587\n",
      "[231]\ttrain-mlogloss:0.412978\ttest-mlogloss:0.555802\n",
      "[232]\ttrain-mlogloss:0.412587\ttest-mlogloss:0.555726\n",
      "[233]\ttrain-mlogloss:0.412173\ttest-mlogloss:0.55565\n",
      "[234]\ttrain-mlogloss:0.411571\ttest-mlogloss:0.555526\n",
      "[235]\ttrain-mlogloss:0.411083\ttest-mlogloss:0.555463\n",
      "[236]\ttrain-mlogloss:0.410468\ttest-mlogloss:0.555399\n",
      "[237]\ttrain-mlogloss:0.409871\ttest-mlogloss:0.555408\n",
      "[238]\ttrain-mlogloss:0.409406\ttest-mlogloss:0.555459\n",
      "[239]\ttrain-mlogloss:0.408818\ttest-mlogloss:0.555429\n",
      "[240]\ttrain-mlogloss:0.408427\ttest-mlogloss:0.555331\n",
      "[241]\ttrain-mlogloss:0.407813\ttest-mlogloss:0.555322\n",
      "[242]\ttrain-mlogloss:0.407491\ttest-mlogloss:0.555331\n",
      "[243]\ttrain-mlogloss:0.407121\ttest-mlogloss:0.555264\n",
      "[244]\ttrain-mlogloss:0.406581\ttest-mlogloss:0.55522\n",
      "[245]\ttrain-mlogloss:0.406207\ttest-mlogloss:0.555194\n",
      "[246]\ttrain-mlogloss:0.405683\ttest-mlogloss:0.555126\n",
      "[247]\ttrain-mlogloss:0.405198\ttest-mlogloss:0.555161\n",
      "[248]\ttrain-mlogloss:0.404614\ttest-mlogloss:0.555052\n",
      "[249]\ttrain-mlogloss:0.404096\ttest-mlogloss:0.555091\n",
      "[250]\ttrain-mlogloss:0.403524\ttest-mlogloss:0.555002\n",
      "[251]\ttrain-mlogloss:0.403052\ttest-mlogloss:0.554882\n",
      "[252]\ttrain-mlogloss:0.402591\ttest-mlogloss:0.554787\n",
      "[253]\ttrain-mlogloss:0.402107\ttest-mlogloss:0.554834\n",
      "[254]\ttrain-mlogloss:0.401672\ttest-mlogloss:0.554685\n",
      "[255]\ttrain-mlogloss:0.401275\ttest-mlogloss:0.554608\n",
      "[256]\ttrain-mlogloss:0.40092\ttest-mlogloss:0.554652\n",
      "[257]\ttrain-mlogloss:0.400413\ttest-mlogloss:0.554592\n",
      "[258]\ttrain-mlogloss:0.399768\ttest-mlogloss:0.554445\n",
      "[259]\ttrain-mlogloss:0.399168\ttest-mlogloss:0.554246\n",
      "[260]\ttrain-mlogloss:0.398764\ttest-mlogloss:0.554178\n",
      "[261]\ttrain-mlogloss:0.398159\ttest-mlogloss:0.554093\n",
      "[262]\ttrain-mlogloss:0.397742\ttest-mlogloss:0.554087\n",
      "[263]\ttrain-mlogloss:0.397128\ttest-mlogloss:0.554121\n",
      "[264]\ttrain-mlogloss:0.396691\ttest-mlogloss:0.554203\n",
      "[265]\ttrain-mlogloss:0.396054\ttest-mlogloss:0.554101\n",
      "[266]\ttrain-mlogloss:0.395643\ttest-mlogloss:0.554044\n",
      "[267]\ttrain-mlogloss:0.395098\ttest-mlogloss:0.553969\n",
      "[268]\ttrain-mlogloss:0.394656\ttest-mlogloss:0.553881\n",
      "[269]\ttrain-mlogloss:0.394284\ttest-mlogloss:0.55389\n",
      "[270]\ttrain-mlogloss:0.393939\ttest-mlogloss:0.553772\n",
      "[271]\ttrain-mlogloss:0.393492\ttest-mlogloss:0.553815\n",
      "[272]\ttrain-mlogloss:0.393149\ttest-mlogloss:0.553793\n",
      "[273]\ttrain-mlogloss:0.392618\ttest-mlogloss:0.553835\n",
      "[274]\ttrain-mlogloss:0.392194\ttest-mlogloss:0.553827\n",
      "[275]\ttrain-mlogloss:0.391611\ttest-mlogloss:0.553716\n",
      "[276]\ttrain-mlogloss:0.391283\ttest-mlogloss:0.55363\n",
      "[277]\ttrain-mlogloss:0.390843\ttest-mlogloss:0.553553\n",
      "[278]\ttrain-mlogloss:0.390415\ttest-mlogloss:0.553527\n",
      "[279]\ttrain-mlogloss:0.390012\ttest-mlogloss:0.553456\n",
      "[280]\ttrain-mlogloss:0.389666\ttest-mlogloss:0.553414\n",
      "[281]\ttrain-mlogloss:0.389219\ttest-mlogloss:0.553458\n",
      "[282]\ttrain-mlogloss:0.388667\ttest-mlogloss:0.553399\n",
      "[283]\ttrain-mlogloss:0.388102\ttest-mlogloss:0.553208\n",
      "[284]\ttrain-mlogloss:0.387625\ttest-mlogloss:0.553237\n",
      "[285]\ttrain-mlogloss:0.387109\ttest-mlogloss:0.553271\n",
      "[286]\ttrain-mlogloss:0.386714\ttest-mlogloss:0.553323\n",
      "[287]\ttrain-mlogloss:0.38641\ttest-mlogloss:0.553292\n",
      "[288]\ttrain-mlogloss:0.385887\ttest-mlogloss:0.553345\n",
      "[289]\ttrain-mlogloss:0.385442\ttest-mlogloss:0.553318\n",
      "[290]\ttrain-mlogloss:0.384934\ttest-mlogloss:0.553294\n",
      "[291]\ttrain-mlogloss:0.384596\ttest-mlogloss:0.553284\n",
      "[292]\ttrain-mlogloss:0.384378\ttest-mlogloss:0.55329\n",
      "[293]\ttrain-mlogloss:0.38406\ttest-mlogloss:0.553205\n",
      "[294]\ttrain-mlogloss:0.383755\ttest-mlogloss:0.553275\n",
      "[295]\ttrain-mlogloss:0.383161\ttest-mlogloss:0.553216\n",
      "[296]\ttrain-mlogloss:0.382806\ttest-mlogloss:0.553147\n",
      "[297]\ttrain-mlogloss:0.382345\ttest-mlogloss:0.55313\n",
      "[298]\ttrain-mlogloss:0.381829\ttest-mlogloss:0.553086\n",
      "[299]\ttrain-mlogloss:0.381193\ttest-mlogloss:0.553005\n",
      "[300]\ttrain-mlogloss:0.380869\ttest-mlogloss:0.552968\n",
      "[301]\ttrain-mlogloss:0.38038\ttest-mlogloss:0.552881\n",
      "[302]\ttrain-mlogloss:0.379877\ttest-mlogloss:0.55281\n",
      "[303]\ttrain-mlogloss:0.379492\ttest-mlogloss:0.55275\n",
      "[304]\ttrain-mlogloss:0.379106\ttest-mlogloss:0.552874\n",
      "[305]\ttrain-mlogloss:0.378643\ttest-mlogloss:0.552871\n",
      "[306]\ttrain-mlogloss:0.378144\ttest-mlogloss:0.552881\n",
      "[307]\ttrain-mlogloss:0.377726\ttest-mlogloss:0.552863\n",
      "[308]\ttrain-mlogloss:0.377195\ttest-mlogloss:0.552899\n",
      "[309]\ttrain-mlogloss:0.376685\ttest-mlogloss:0.552888\n",
      "[310]\ttrain-mlogloss:0.37636\ttest-mlogloss:0.552791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[311]\ttrain-mlogloss:0.376064\ttest-mlogloss:0.552764\n",
      "[312]\ttrain-mlogloss:0.37577\ttest-mlogloss:0.552748\n",
      "[313]\ttrain-mlogloss:0.375404\ttest-mlogloss:0.552718\n",
      "[314]\ttrain-mlogloss:0.375078\ttest-mlogloss:0.552658\n",
      "[315]\ttrain-mlogloss:0.374569\ttest-mlogloss:0.552639\n",
      "[316]\ttrain-mlogloss:0.374074\ttest-mlogloss:0.55255\n",
      "[317]\ttrain-mlogloss:0.373552\ttest-mlogloss:0.55249\n",
      "[318]\ttrain-mlogloss:0.373138\ttest-mlogloss:0.552515\n",
      "[319]\ttrain-mlogloss:0.372849\ttest-mlogloss:0.552519\n",
      "[320]\ttrain-mlogloss:0.372492\ttest-mlogloss:0.552481\n",
      "[321]\ttrain-mlogloss:0.372004\ttest-mlogloss:0.552545\n",
      "[322]\ttrain-mlogloss:0.371691\ttest-mlogloss:0.552632\n",
      "[323]\ttrain-mlogloss:0.371354\ttest-mlogloss:0.552538\n",
      "[324]\ttrain-mlogloss:0.370886\ttest-mlogloss:0.552501\n",
      "[325]\ttrain-mlogloss:0.370575\ttest-mlogloss:0.552414\n",
      "[326]\ttrain-mlogloss:0.370066\ttest-mlogloss:0.5524\n",
      "[327]\ttrain-mlogloss:0.369841\ttest-mlogloss:0.552354\n",
      "[328]\ttrain-mlogloss:0.369375\ttest-mlogloss:0.55241\n",
      "[329]\ttrain-mlogloss:0.368993\ttest-mlogloss:0.552366\n",
      "[330]\ttrain-mlogloss:0.368616\ttest-mlogloss:0.552337\n",
      "[331]\ttrain-mlogloss:0.368233\ttest-mlogloss:0.552271\n",
      "[332]\ttrain-mlogloss:0.36797\ttest-mlogloss:0.552247\n",
      "[333]\ttrain-mlogloss:0.367489\ttest-mlogloss:0.552206\n",
      "[334]\ttrain-mlogloss:0.367038\ttest-mlogloss:0.552283\n",
      "[335]\ttrain-mlogloss:0.366686\ttest-mlogloss:0.552233\n",
      "[336]\ttrain-mlogloss:0.366277\ttest-mlogloss:0.552132\n",
      "[337]\ttrain-mlogloss:0.365877\ttest-mlogloss:0.55206\n",
      "[338]\ttrain-mlogloss:0.365311\ttest-mlogloss:0.552138\n",
      "[339]\ttrain-mlogloss:0.36491\ttest-mlogloss:0.552134\n",
      "[340]\ttrain-mlogloss:0.36438\ttest-mlogloss:0.55217\n",
      "[341]\ttrain-mlogloss:0.36392\ttest-mlogloss:0.552122\n",
      "[342]\ttrain-mlogloss:0.363519\ttest-mlogloss:0.552111\n",
      "[343]\ttrain-mlogloss:0.363111\ttest-mlogloss:0.552152\n",
      "[344]\ttrain-mlogloss:0.362745\ttest-mlogloss:0.552132\n",
      "[345]\ttrain-mlogloss:0.36237\ttest-mlogloss:0.552231\n",
      "[346]\ttrain-mlogloss:0.361911\ttest-mlogloss:0.552309\n",
      "[347]\ttrain-mlogloss:0.361509\ttest-mlogloss:0.552371\n",
      "[348]\ttrain-mlogloss:0.361187\ttest-mlogloss:0.552442\n",
      "[349]\ttrain-mlogloss:0.360657\ttest-mlogloss:0.552391\n",
      "[350]\ttrain-mlogloss:0.360271\ttest-mlogloss:0.552502\n",
      "[351]\ttrain-mlogloss:0.359866\ttest-mlogloss:0.552364\n",
      "[352]\ttrain-mlogloss:0.359504\ttest-mlogloss:0.552249\n",
      "[353]\ttrain-mlogloss:0.359145\ttest-mlogloss:0.552229\n",
      "[354]\ttrain-mlogloss:0.358735\ttest-mlogloss:0.552259\n",
      "[355]\ttrain-mlogloss:0.358241\ttest-mlogloss:0.552222\n",
      "[356]\ttrain-mlogloss:0.358032\ttest-mlogloss:0.552191\n",
      "[357]\ttrain-mlogloss:0.357573\ttest-mlogloss:0.552161\n",
      "Stopping. Best iteration:\n",
      "[337]\ttrain-mlogloss:0.365877\ttest-mlogloss:0.55206\n",
      "\n",
      "[0.5521611861930136]\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2016)\n",
    "for dev_index, val_index in kf.split(range(train_X.shape[0])):\n",
    "        dev_X, val_X = train_X[dev_index,:], train_X[val_index,:]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y)\n",
    "        cv_scores.append(log_loss(val_y, preds))\n",
    "        print(cv_scores)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df[features_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
